{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_metrics(predictions):\n",
    "#     # 计算真正例（TP）、假正例（FP）、真负例（TN）、假负例（FN）\n",
    "#     TP = sum(predictions)  # 真正例数量等于预测为1且实际为1的样本数\n",
    "#     FP = len(predictions) - TP  # 假正例数量等于预测为1且实际为0的样本数\n",
    "#     TN = 0  # 实际不存在\n",
    "#     FN = 0  # 实际不存在\n",
    "\n",
    "#     # 计算准确率\n",
    "#     accuracy = TP / len(predictions)\n",
    "\n",
    "#     # 计算召回率\n",
    "#     if TP + FN != 0:\n",
    "#         recall = TP / (TP + FN)\n",
    "#     else:\n",
    "#         recall = 0\n",
    "\n",
    "#     # 计算 F1 分数\n",
    "#     if TP + FP != 0 and TP + FN != 0:\n",
    "#         f1_score = 2 * TP / (2 * TP + FP + FN)\n",
    "#     else:\n",
    "#         f1_score = 0\n",
    "\n",
    "#     return accuracy, recall, f1_score\n",
    "\n",
    "# # 示例使用\n",
    "# predictions = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]  # 示例预测结果\n",
    "# accuracy, recall, f1_score = calculate_metrics(predictions)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# val = ['B-poiCollection', 'B-poiCollection', 'B-poiCollection', 'I-poiCollection', 'B-poiCollection', 'I-poiCollection', 'E-poiCollection', 'E-poiCollection', 'I-houseNumber', 'I-houseNumber', 'I-houseNumber', 'I-houseNumber', 'I-houseNumber']\n",
    "# v = np.array(val)\n",
    "# v = np.where(v == 'B-poiCollection', 1, 0)\n",
    "# v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = ['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有这样的一组标注分别是B-poi,I-poi,E-poi,S-poi, 分别是如下意思:\n",
    "B-poi: 词的开始\n",
    "I-poi: 词的中间, 一个词如果只有两个字, 那么I就不存在\n",
    "E-poi: 词的结束\n",
    "S-poi: 单独成词\n",
    "\n",
    "现在含有以上标签的的一个数组, 类似['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']\n",
    "\n",
    "请用python代码统计词的数量. 例如上面的例子中, 词的数量是10, 注意, 非法的标签也单独成词\n",
    "分别是['B-poi','I-poi','E-poi'], ['B-poi'], ['B-poi'], ['B-poi'], ['B-poi','E-poi'], ['I-poi'], ['I-poi'], ['I-poi', 'E-poi'], ['E-poi'], ['S-poi']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = ['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']\n",
    "# stack = []\n",
    "# predict_one_group = []\n",
    "# for i, token in enumerate(tags):\n",
    "#   if token == 'S-poi':\n",
    "#     predict_one_group.append([(token, i)])\n",
    "#     continue\n",
    "\n",
    "#   if len(stack) == 0:\n",
    "#     stack.append((token, i))\n",
    "#     continue\n",
    "\n",
    "#   last_token, _ = stack[-1]\n",
    "#   if last_token == 'B-poi' and token == 'I-poi' or last_token == 'B-poi' and token == 'E-poi' or last_token == 'I-poi' and token == 'E-poi':\n",
    "#     stack.append((token, i))\n",
    "#   else:\n",
    "#     predict_one_group.append(stack)\n",
    "#     stack = [(token, i)]\n",
    "\n",
    "# if len(stack) > 0:\n",
    "#   predict_one_group.append(stack)\n",
    "\n",
    "# print(\"词的列表是：\", predict_one_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = ['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','S-city', 'I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']\n",
    "# predict_one_group = group_tokens(tokens, 'poi')\n",
    "# print(predict_one_group)\n",
    "# print(len(predict_one_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = \"上海市浦东新区张江镇汉东居委会\"\n",
    "# tokens = ['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','S-city', 'I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']\n",
    "# predict_one_group = group_tokens(tokens, 'poi')\n",
    "\n",
    "# texts = trans_group_token_to_text(predict_one_group, raw)\n",
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "将一组展开的token, 归并合理的组\n",
    "\"\"\"\n",
    "def group_tokens(tokens, category):\n",
    "  stack = []\n",
    "  group = []\n",
    "  for i, token in enumerate(tokens):\n",
    "    if token not in [f'B-{category}', f'I-{category}', f'E-{category}', f'S-{category}']:\n",
    "      continue      \n",
    "\n",
    "    if token == f'S-{category}':\n",
    "      group.append([(token, i)])\n",
    "      continue\n",
    "\n",
    "    if len(stack) == 0:\n",
    "      stack.append((token, i))\n",
    "      continue\n",
    "\n",
    "    last_token, _ = stack[-1]\n",
    "\n",
    "    if last_token == f'B-{category}' and token == f'I-{category}' or last_token == f'B-{category}' and token == f'E-{category}' or last_token == f'I-{category}' and token == f'E-{category}':\n",
    "      stack.append((token, i))\n",
    "    else:\n",
    "      group.append(stack)\n",
    "      stack = [(token, i)]\n",
    "\n",
    "  if len(stack) > 0:\n",
    "    group.append(stack)\n",
    "\n",
    "  return sorted(group, key=lambda x: x[0][1])\n",
    "\n",
    "def batch_group_tokens(batch_tokens, category):\n",
    "  batch_group = []\n",
    "  for tokens in batch_tokens:\n",
    "    batch_group.append(group_tokens(tokens, category))\n",
    "  return batch_group\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "统计的结果\n",
    "predict_group: 预测的group\n",
    "y_group: 真实的group\n",
    "note: 所有的group只保留了特定的category\n",
    "\"\"\"\n",
    "def statistics_group(predict_group, y_group):\n",
    "\n",
    "  if len(predict_group) == 0 or len(y_group) == 0:\n",
    "    return [], [], [], [], 0, 0\n",
    "\n",
    "  # 预测成功的\n",
    "  correct = []\n",
    "\n",
    "  # 编码错误的\n",
    "  error_encode = []\n",
    "\n",
    "  # 预测失败的\n",
    "  error_result = []\n",
    "\n",
    "  # 未知错误的\n",
    "  error_unknow = []\n",
    "\n",
    "  # 准确率\n",
    "  precision = 0\n",
    "\n",
    "  # 召回率\n",
    "  recall = 0\n",
    "\n",
    "  # 预测失败的\n",
    "  for predict_one_group in predict_group:\n",
    "    if predict_one_group in y_group:\n",
    "      correct.append(predict_one_group)\n",
    "      continue\n",
    "\n",
    "    # 上面的条件排除了预测成功的, 剩下只有预测失败的和编码错误的\n",
    "\n",
    "    # 只有一个长度, 代表肯定不是编码错误, 上面不排除是预测成功, 所以是预测错误\n",
    "    if len(predict_one_group) == 1:\n",
    "      if predict_one_group[0][0].startswith('S'):\n",
    "        error_result.append(predict_one_group)\n",
    "    else:\n",
    "      \"\"\"\n",
    "      长度大于1的情况: 有几种可能:\n",
    "      1. 预测错误: 如有交集, 也就是当前的group下标在y中有元素跟他下标有交集, 那么是预测错误\n",
    "      2. 如果没有交集\n",
    "      2.1 编码错误: 不能编码\n",
    "      2.2 未知错误: 可以编码\n",
    "      \"\"\"\n",
    "      # 长度\n",
    "      # 暂时这个策略 v0.1.0\n",
    "      # 长度大于1的情况, 如果当前的group下标在y中有元素跟他下标有交集, 那么是预测错误, 如果没有交集, 那么是编码错误\n",
    "      # 有没有部分预测对的\n",
    "      intersection = False\n",
    "      intersection_index = -1\n",
    "      for i, y_one_group in enumerate(y_group):\n",
    "        if len(set([x[1] for x in predict_one_group]) & set([x[1] for x in y_one_group])) > 0:\n",
    "          intersection = True\n",
    "          intersection_index = i\n",
    "          break\n",
    "\n",
    "      if intersection:\n",
    "        error_result.append({'predict': predict_one_group, 'y': y_group[intersection_index]})\n",
    "      else:\n",
    "        # 判断是否可以编码\n",
    "        if predict_one_group[0][0].startswith('B') and predict_one_group[-1][0].startswith('E'):\n",
    "          error_unknow.append(predict_one_group)\n",
    "        else:\n",
    "          error_encode.append(predict_one_group)\n",
    "\n",
    "    \n",
    "  # 计算准确率\n",
    "  precision = len(correct) / len(predict_group)\n",
    "\n",
    "  # 计算召回率\n",
    "  recall = len(correct) / len(y_group)\n",
    "\n",
    "  return correct, error_result, error_encode, error_unknow, precision, recall\n",
    "\n",
    "\n",
    "def batch_statistics_group(batch_predict_group, batch_y_group):\n",
    "  corrects = []\n",
    "  error_results = []\n",
    "  error_encodes = []\n",
    "  error_unknows = []\n",
    "  precisions = []\n",
    "  recalls = []\n",
    "  precision_mean = 0\n",
    "  recall_mean = 0\n",
    "\n",
    "  for predict_group, y_group in zip(batch_predict_group, batch_y_group):\n",
    "    correct, error_result, error_encode, error_unknow, precision, recall = statistics_group(predict_group, y_group)\n",
    "    corrects.append(correct)\n",
    "    error_results.append(error_result)\n",
    "    error_encodes.append(error_encode)\n",
    "    error_unknows.append(error_unknow)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "  \n",
    "  if len(precisions) > 0:\n",
    "    precision_mean = sum(precisions) / len(precisions)\n",
    "  \n",
    "  if len(recalls) > 0:\n",
    "    recall_mean = sum(recalls) / len(recalls)\n",
    "\n",
    "  return corrects, error_results, error_encodes, error_unknows, precisions, recalls, precision_mean, recall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: [[('B-poi', 0), ('I-poi', 1), ('E-poi', 2)], [('S-poi', 14)]]\n",
      "error_result: [{'predict': [('B-poi', 6), ('E-poi', 7)], 'y': [('B-poi', 4), ('I-poi', 5), ('E-poi', 6)]}, {'predict': [('I-poi', 11), ('E-poi', 12)], 'y': [('B-poi', 9), ('I-poi', 10), ('E-poi', 11)]}]\n",
      "error_encode: []\n",
      "error_unknow: []\n",
      "precision: 0.2\n",
      "recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_tokens = ['B-poi','I-poi','E-poi','B-poi','B-poi','B-poi','B-poi','E-poi','S-city', 'I-poi','I-poi','I-poi','E-poi','E-poi', 'S-poi']\n",
    "y_tokens = ['B-poi','I-poi','E-poi','S-poi','B-poi','I-poi','E-poi','E-poi','S-city', 'B-poi','I-poi','E-poi','E-poi','S-poi', 'S-poi']\n",
    "predict_group = group_tokens(predict_tokens, 'poi')\n",
    "y_group = group_tokens(y_tokens, 'poi')\n",
    "correct, error_result, error_encode, error_unknow, precision, recall = statistics_group(predict_group, y_group)\n",
    "print(f'correct: {correct}')\n",
    "print(f'error_result: {error_result}')\n",
    "print(f'error_encode: {error_encode}')\n",
    "print(f'error_unknow: {error_unknow}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv数据\n",
    "import csv\n",
    "y = []\n",
    "with open('../input/eval_y.csv', mode='r', encoding='utf-8') as file:\n",
    "  reader = csv.reader(file)\n",
    "  for row in reader:\n",
    "    y.append(row)\n",
    "\n",
    "predict = []\n",
    "with open('../input/eval_predict.csv', mode='r', encoding='utf-8') as file:\n",
    "  reader = csv.reader(file)\n",
    "  for row in reader:\n",
    "    predict.append(row)\n",
    "\n",
    "r = []\n",
    "with open('../input/eval_token.csv', mode='r', encoding='utf-8') as file:\n",
    "  reader = csv.reader(file)\n",
    "  for row in reader:\n",
    "    r.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_category = ['transitLine', 'floor', 'subpoi', 'road', 'otherinfo', 'poiCollection', 'poi', 'cls', 'sep', 'community', 'room', 'devZone', 'neighborhood', 'assist', 'country', 'subArea', 'province', 'aoi', 'township', 'building', 'district', 'redundant', '_PAD', 'station', 'crossing', 'cell', 'city', 'houseNumber', 'sideRoad', 'village', 'villageGroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def trans_group(group, raw):\n",
    "  start = group[0][1]\n",
    "  end = group[-1][1]\n",
    "  return ''.join(raw[start:end+1])\n",
    "\n",
    "def eval(predict, y, r, unique_category, log=False, directory=None):\n",
    "  assert len(predict) == len(y) == len(r)\n",
    "\n",
    "  all_precision_mean = []\n",
    "  all_recall_mean = []\n",
    "  \n",
    "  for category in unique_category:\n",
    "    predict_group = batch_group_tokens(predict, category)\n",
    "    y_group = batch_group_tokens(y, category)\n",
    "    corrects, error_results, error_encodes, error_unknows, precisions, recalls, precision_mean, recall_mean = batch_statistics_group(predict_group, y_group)\n",
    "    if log:\n",
    "      os.makedirs(directory, exist_ok=True)\n",
    "      \n",
    "      # 拼接文件路径\n",
    "      timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "      # 预测错误\n",
    "      lines = []\n",
    "      for errors, raw in zip(error_results, r):\n",
    "        if len(errors) == 0:\n",
    "          continue\n",
    "        for e in errors:\n",
    "          predict_text = trans_group(e['predict'], raw)\n",
    "          y_text = trans_group(e['y'], raw)\n",
    "          lines.append(f\"{predict_text},{y_text},{category}\")\n",
    "\n",
    "      if len(lines) > 0:\n",
    "        with open(os.path.join(directory, f\"error-results-{category}-{timestamp}.csv\"), mode='w', encoding='utf-8') as file:\n",
    "          file.write('\\n'.join(lines))\n",
    "\n",
    "\n",
    "\n",
    "      # 编码错误\n",
    "      lines = []\n",
    "      for errors, raw in zip(error_encodes, r):\n",
    "        if len(errors) == 0:\n",
    "          continue\n",
    "        for e in errors:\n",
    "          encode_text = trans_group(e, raw)\n",
    "          lines.append(f\"{encode_text},{category}\")\n",
    "\n",
    "      if len(lines) > 0:\n",
    "        with open(os.path.join(directory, f\"error-encodes-{category}-{timestamp}.csv\"), mode='w', encoding='utf-8') as file:\n",
    "          file.write('\\n'.join(lines))\n",
    "\n",
    "  \n",
    "      # 未知错误\n",
    "      lines = []\n",
    "      for errors, raw in zip(error_unknows, r):\n",
    "        if len(errors) == 0:\n",
    "          continue\n",
    "        for e in errors:\n",
    "          unknow_text = trans_group(e, raw)\n",
    "          lines.append(f\"{unknow_text},{category}\")\n",
    "\n",
    "      if len(lines) > 0:\n",
    "        with open(os.path.join(directory, f\"error-unknows-{category}-{timestamp}.csv\"), mode='w', encoding='utf-8') as file:\n",
    "          file.write('\\n'.join(lines))\n",
    "\n",
    "    if precision_mean > 0:\n",
    "      all_precision_mean.append(precision_mean)\n",
    "    if recall_mean > 0:\n",
    "      all_recall_mean.append(recall_mean)\n",
    "\n",
    "    print(f'precisions: {precision_mean}, recalls: {recall_mean}, category: {category}')\n",
    "\n",
    "  if len(precisions) > 0:\n",
    "    precision = sum(all_recall_mean) / len(all_recall_mean)\n",
    "  \n",
    "  if len(recalls) > 0:\n",
    "    recall = sum(recalls) / len(recalls)\n",
    "\n",
    "  f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "  return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisions: 0.0, recalls: 0.0, category: transitLine\n",
      "precisions: 0.0, recalls: 0.0, category: floor\n",
      "precisions: 0.0, recalls: 0.0, category: subpoi\n",
      "precisions: 0.060546875, recalls: 0.029003906249999996, category: road\n",
      "precisions: 0.0, recalls: 0.0, category: otherinfo\n",
      "precisions: 0.043598051300771365, recalls: 0.10200182025707646, category: poiCollection\n",
      "precisions: 0.0, recalls: 0.0, category: poi\n",
      "precisions: 0.0, recalls: 0.0, category: cls\n",
      "precisions: 0.0, recalls: 0.0, category: sep\n",
      "precisions: 0.0, recalls: 0.0, category: community\n",
      "precisions: 0.0, recalls: 0.0, category: room\n",
      "precisions: 0.0, recalls: 0.0, category: devZone\n",
      "precisions: 0.0, recalls: 0.0, category: neighborhood\n",
      "precisions: 0.0, recalls: 0.0, category: assist\n",
      "precisions: 0.0, recalls: 0.0, category: country\n",
      "precisions: 0.0, recalls: 0.0, category: subArea\n",
      "precisions: 0.0, recalls: 0.0, category: province\n",
      "precisions: 0.0, recalls: 0.0, category: aoi\n",
      "precisions: 0.0, recalls: 0.0, category: township\n",
      "precisions: 0.0, recalls: 0.0, category: building\n",
      "precisions: 0.0, recalls: 0.0, category: district\n",
      "precisions: 0.0, recalls: 0.0, category: redundant\n",
      "precisions: 0.0, recalls: 0.0, category: _PAD\n",
      "precisions: 0.0, recalls: 0.0, category: station\n",
      "precisions: 0.0, recalls: 0.0, category: crossing\n",
      "precisions: 0.0, recalls: 0.0, category: cell\n",
      "precisions: 0.0, recalls: 0.0, category: city\n",
      "precisions: 0.025216149410485316, recalls: 0.04792751736111118, category: houseNumber\n",
      "precisions: 0.0, recalls: 0.0, category: sideRoad\n",
      "precisions: 0.0, recalls: 0.0, category: village\n",
      "precisions: 0.0, recalls: 0.0, category: villageGroup\n",
      "precision: 0.05964441462272921, recall: 0.0, f1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score = eval(predict, y, r, unique_category, True, './eval-result')\n",
    "print(f'precision: {precision}, recall: {recall}, f1_score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'key1': ['value1', 'value2'],\n",
       "             'key2': ['value3', 'value4'],\n",
       "             'key3': ['value5']})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 假设你有两个字典：\n",
    "dict1 = {'key1': ['value1', 'value2'], 'key2': ['value3']}\n",
    "dict2 = {'key2': ['value4'], 'key3': ['value5']}\n",
    "\n",
    "# 创建一个 defaultdict，其默认值为一个空列表\n",
    "merged_dict = defaultdict(list)\n",
    "\n",
    "# 将 dict1 和 dict2 的键值对添加到 merged_dict 中\n",
    "for d in (dict1, dict2):  # 可以添加更多的字典\n",
    "    for key, value in d.items():\n",
    "        merged_dict[key].extend(value)\n",
    "\n",
    "# 此时，merged_dict 的内容为：\n",
    "# {'key1': ['value1', 'value2'], 'key2': ['value3', 'value4'], 'key3': ['value5']}\n",
    "merged_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
